# 비동기 프로그래밍에서 자주 등장하는 이벤트 루프는 무엇인가?

최근 Redis를 공부하면서, ‘Redis는 싱글 스레드로 동작한다’는 말을 자주 접하게 되었다. 그런데 조금 더 들여다보니, 단순히 모든 것을 한 스레드에서 처리하는 것이 아니라, 클라이언트 커맨드 실행은 싱글 이벤트 루프에서 처리하고, 일부 오래 걸리는 작업은 백그라운드 스레드에서 수행하는 구조였다.

또한 I/O 멀티스레드 기능이 별도로 존재한다는 것도 알게 되었다. 이 과정을 공부하면서 Redis뿐만 아니라 Node.js, Netty, Tomcat NIO 같은 다양한 시스템이 각기 다른 방식으로 이벤트 루프를 활용한다는 점이 흥미로웠다. 특히 Tomcat처럼 애플리케이션 로직은 전통적인 Thread-per-Request로 실행하지만, 내부 Connector 레벨에서는 이벤트 루프를 사용해 HTTP 요청을 조립하는 구조가 인상 깊었다.

그래서 이번 글에서는 Redis, Node.js, Netty, Tomcat NIO의 이벤트 루프 구조와 각 시스템이 어떤 범위까지 이벤트 루프를 적용하는지 정리해 보았으며, 정확하게 이벤트 루프가 어떤 특징을 가지고 있는지, 주의해야 될 점은 무엇인지도 함께 정리해보았다.



## 이벤트 루프 사용 이유

이벤트 루프(Event Loop)는 처리 시간이 오래 걸리는 I/O 작업을 효율적으로 다루기 위해 널리 사용되는 구조다. I/O 작업이 완료될 때까지 스레드가 대기하는 대신, 준비가 된 다른 요청들을 처리하여 스레드 활용도를 높인다. 대규모 네트워크 연결을 동시에 다루어야 하는 서버나 메시지 브로커, 데이터베이스, 웹 서버 등에서는 대부분 이벤트 루프를 기반으로 동작하며, 내부적으로는 epoll, kqueue, IOCP와 같은 I/O 멀티플렉싱 기법을 사용한다.



## 다양한 이벤트 루프 사용 사례

### Redis

Redis는 대표적인 싱글 이벤트 루프 아키텍처를 채택한 시스템이다. 네트워크 I/O와 클라이언트 커맨드 실행 모두 단일 스레드에서 처리한다. 다만 오래 걸리는 작업, 예를 들어 UNLINK, FLUSHALL ASYNC, AOF rewrite, RDB save, 키 만료 처리 등은 백그라운드 스레드에서 실행하여 메인 루프의 지연을 줄인다. Redis 6.0부터는 읽기/쓰기 네트워크 I/O를 병렬로 처리할 수 있는 I/O 멀티스레드 기능이 추가되었지만, 커맨드 실행 자체는 여전히 싱글 이벤트 루프에서 수행된다.

### Node.js

Node.js 역시 싱글 이벤트 루프를 기반으로 한다. libuv 라이브러리 위에서 네트워크 I/O, 타이머, 콜백 실행을 모두 메인 이벤트 루프 스레드에서 처리한다. 파일 시스템 접근이나 CPU 연산처럼 블로킹 가능성이 있는 작업은 libuv의 워커 스레드 풀로 넘겨 병렬 처리한다. 구조적으로는 Redis와 비슷하게 “메인 로직은 싱글 루프, 일부 작업은 백그라운드 스레드” 형태지만, 내부 구현과 스레드 풀 활용 방식은 서로 다르다.

### Netty

Java 개발자라면 이벤트 루프를 들었을 때 아마 Netty를 많이 생각할텐데 Java의 Netty는 멀티 스레드 이벤트 루프 그룹(EventLoopGroup) 구조를 사용한다. 각 이벤트 루프 스레드는 여러 채널(소켓 연결)의 I/O 이벤트를 관리하며, 채널은 생성 시 특정 이벤트 루프에 바인딩되어 해당 스레드에서만 처리된다. I/O 이벤트뿐 아니라 대부분의 채널 핸들러 로직도 같은 이벤트 루프 스레드에서 실행된다. 따라서 한 채널의 핸들러 로직이 오래 걸리면, 그 채널의 다음 I/O 처리가 지연될 수 있다.

이벤트 루프는 공통적으로, I/O 멀티플렉싱과 비동기 이벤트 분배라는 기본 원리를 바탕으로 스레드 효율과 처리량을 극대화한다. 어떤 범위까지 이벤트 루프에서 처리하고 어떤 작업을 별도 스레드로 분리하느냐가 핵심이며, 해결하려는 문제에 따라 싱글 루프 방식과 다중 루프 방식으로 나눠지는 것 같다. Redis와 Node.js는 주요 로직이 싱글 루프에서 수행되고, Netty는 멀티 이벤트 루프 스레드로 I/O를 처리한다. 하지만 Netty의 멀티 이벤트 루프도 결국 이벤트 루프 스레드가 이벤트 큐를 내부에 개별적으로 소유하여 처리하기 때문에 하나의 스레드가 한 개의 이벤트 큐를 처리하는 방식은 동일하다.



## 이벤트 루프에서 사용하는 멀티플레싱 기반의 다중 접속 서버

### 소켓

![img](https://vos.line-scdn.net/landpress-content-v2_954/1663603039179.png?updatedAt=1663603039000)

- 두 개의 프로세스가 특정 포트를 통해 양방향 통신이 가능하도록 만들어 주는 추상화된 장치
- 사용자 메모리 공간에 존재하는 프로세서는 커널 공간에 생성된 소켓을 통해 데이터를 송수신
- 소켓의 구성 요소
  - 로컬 IP, Port
  - 상대방 IP, Port
  - 수신 버퍼: 소켓이 연결 된 후 데이터가 들어오면 수신 버퍼에 수신 데이터를 씀
  - 송신 버퍼: 데이터를 보낼 때 송신 버퍼에 데이터를 씀



### 전통적인 방식의 소켓 서버

![img](https://vos.line-scdn.net/landpress-content-v2_1761/1672029326745.png?updatedAt=1672029327000)

#### 서버

- 클라이언트의 데이터 요청 -> 일종의 데이터 전송
- 연결 요청을 받기 위해서는 하나의 소켓이 필요하며 이를 **서버 소켓** 또는 **리스닝 소켓**이라 함
- `listen()` : 소켓을 리스닝 소켓으로 만들어 연결 요청을 받음
- `accept()` : 서버 소켓을 통해 글라이언트의 연결 요청을 받으면, 연결 요청 정보를 참조해 클라이언트 소켓과의 통신을 위한 **별도의 소켓**을 하나 더 생성
- 새로 생성된 소켓을 대상으로 데이터의 송수신이 진행

#### 클라이언트

- 소켓을 생성하고, 연결 요청을 위해 `connect()` 호출이 전부
- 서버의 `listen()` 함수 호출 이후(서버 소켓이 준비된 이후)에만 `connect()` 함수 호출을 통해 연결 가능

#### 문제점

- 다수의 클라이언트가 연결하는 경우에 문제 발생
- 처음 연결한 클라이언트가 연결을 종료하기 전까지 다른 클라이언트의 연결은 **Listen Queue**에 대기
- 둘 이상의 클라이언트가 동시에 접속해 서버의 서비스를 받기 위해서는 **다중 접속 서버** 구현 필요
  - **멀티프로세싱 기반 서버**: 프로세스를 다수 생성하는 방식
  - **멀티스레딩 기반 서버**: 스레드를 다수 생성하는 방식
  - **멀티플렉싱 기반 서버**: 입출력 대상을 묶어서 관리하는 방식



### 멀티프로세싱 기반 다중 접속 서버

![img](https://vos.line-scdn.net/landpress-content-v2_954/1663603730433.png?updatedAt=1663603731000)

- 다수의 프로세스를 생성하는 방식으로 서비스 제공

  1. 부모 프로세스는 리스닝 소켓으로 `accept()`함수를 호출해서 연결 요청을 수락
  2. 소켓의 **파일 디스크립터(클라이언트와 연결된 연결 소켓)**를 자식 프로세스를 생성해 넘김
  3. 자식 프로세스는 전달받은 파일 디스크립터를 바탕으로 서비스를 제공

- 하나의 연결이 생성될 때마다 프로세스를 생성해서 해당 클라이언트에 대해 서비스를 제공하는 것이 핵심

- 장점

  - 프로그램 흐름이 단순
  - 안정적인 동작 가능
  - 운영체제에서 프로세스는 서로 독립된 실행 객체로 존재하고, 서로 독립된 메모리 공간을 갖기 때문에 서로 영향을 주지 않음

- 단점

  - 프로세스 복사가 필요하기 때문에 리소스를 많이 사용(프로세스는 가장 많은 리소스를 필요하는 형태)
  - 병렬로 처리해야 하는 수만큼 프로세스 생성해야 함

  - 서로 다른 독립적인 메모리 공간으로 인해 프로세스 간 정보 교환 어려움



### 멀티스레딩 기반의 다중 접속 서버

![img](https://vos.line-scdn.net/landpress-content-v2_954/1663604015232.png?updatedAt=1663604016000)

- 다수의 스레드를 생성하는 방식으로 서비스 제공
  1. 메인 스레드가 리스닝 소켓으로 `accept()` 함수를 호출해서 연결 요청 수락
  2. 이때 얻은 소켓의 파일 디스크립터(클라이언트와 연결된 연결 소켓)를 별도 워커 스레드를 생성해 넘겨줌
  3. 워커 스레드는 전달 받은 파일 디스크립터를 바탕으로 서비스 제공
- 하나의 연결이 생성될 때마다 스레드를 생성해서 해당 클라이언트에게 서비스 제공
- 장점
  - 프로세스 복사 비용보다 스레드 생성 비용이 적음
  - 서로 공유하는 메모리가 있어 스레드 간 정보 교환 쉬움
- 단점
  - 하나의 프로세스 내 다수의 스레드가 존재하므로, 하나의 스레드에 문제가 발생하면 전체 프로세스에 영향을 줌으로써 다수의 스레드에 영향 전파할 수 있음
  - 비용은 상대적으로 적게 들지만 스레드 관리에 여전히 많은 리소스 필요
  - 스레드 풀을 사용할 수 있으나 요청마다 스레드를 무한정 생성할 수 없으므로 많은 수의 요청을 동시에 처리하지 못함
- I/O 멀티플렉싱 기법을 사용하여 클라이언트 당 스레드를 하나의 스레드에서 다수의 클라이언트에 연결된 소켓(파일 디스크립터)를 관리하면서 소켓에 이벤트(write/read)가 발생할 때만 해당 이벤트를 처리하도록 구현하여 더 적은 리소스 사용하도록 개선 가능



### 멀티플렉싱 기반의 다중 접속 서버

#### 입출력 다중화

- 하나의 프로세스 혹은 스레드에서 입력과 출력을 모두 다룸

- 커널에서는 하나의 스레드가 여러 개의 소켓(파일 디스크립터)을 다룰 수 있는 **select, poll, epoll, io_uring**고과 같은 시스템 콜(system call)을 제공

- 입출력 함수가 블록킹 되면 입출력 데이터가 준비될 때까지 무한정 블록되기 때문에 하나의 프로세스나 스레드에서 한개의 클라이언트에 대한 입출력만을 처리했음

- I/O 멀티플렉싱을 사용

  - 입출력 함수 자체는 여전히 블록킹

  - 입출력 함수를 호출하기 전 어떤 파일(소켓)에서 입출력이 준비됐는지 이벤트를 확인하여 처리하는 방식으로 블록킹을 최소화

#### 블록킹 I/O

![img](https://vos.line-scdn.net/landpress-content-v2_954/1663604281440.png?updatedAt=1663604282000)

- 애플리케이션에서의 I/O 작업
  - 데이터가 사용할 수 있는 상태로 준비될 때까지 **스레드 대기**
    - 예) 소켓에서 **read**를 수행할 때, 데이터가 네트워크를 통해 도착할 때까지 기다리며, 패킷이 네트워크를 통해 도착하면 **커널 내 버퍼(Recv-Q)**에 복사
  - 애플리케이션은 사용자 모드일 때 사용자 공간에만 접근할 수 있기 때문에 데이터를 사용하기 위해서는 **커널 내 버퍼**에 복사된 데이터를 **커널 공간**에서 **사용자 공간**으로 복사 필요
  - 스레드가  `read()` 함수 호출하여 소켓의 데이터를 읽기
    - 네트워크 -> 커널 내 버퍼 -> 사용자 공간의 프로세스 버퍼 -> **시스템 콜 반환**

#### I/O 멀티플렉싱 모델

![img](https://vos.line-scdn.net/landpress-content-v2_954/1663604384989.png?updatedAt=1663604385000)

- `select()` 함수 호출 -> 여러 개의 소켓 중 `read()` 함수 호출이 가능한 소켓이 생길 때까지 대기
- `selct()` 함수에서 `read()` 함수 호출 가능한 소켓 목록이 반환되면, 해당 소켓들에 대해서 `read()`함수 호출
- 블록킹과 멀티플렉싱의 차이
  - 블록킹 I/O 모델: 하나의 소켓에 대해 데이터의 도착 여부를 확인하며 대기
  - 멀티플렉싱 I/O 모델: 여러 소켓을 동시에 확인하여 하나 이상의 사용 가능한 소켓이 준비될 때까지 대기

##### select(c언어 서버)

![img](https://vos.line-scdn.net/landpress-content-v2_954/1663604517073.png?updatedAt=1663604517000)

- 이벤트(입력, 출력, 에러) 별 감시할 파일들을 파일 상태 테이블에 등록

- 등록된 파일에 이벤트가 발생하면 확인하는 방식으로 동작

- 장점

  - 단일 프로세스(스레드)에서 여러 파일의 입출력을 처리

  - 동시에 수만 개의 커넥션을 한 스레드에서 처리 가능

  - POSIX(Portable Operating System Interface) 표준을 따르기 때문에 지원하는 운영체제 많아 이식성 좋음

  - 클라이언트 요청 마다 별도의 스레드를 생성하지 않기 때문에 컨텍스트 스위칭 오버헤드 발생 하지 않음

- 단점

  - select 함수에 전달하는 정보는 커널에 등록되지 않은 정보라서 매번 호출할 때마다 관련 정보를 전달해야 함
  - select 함수 반환 결과는 이벤트가 발생한 파일 디스크립터 개수이기 때문에 어떤 파일 디스크립터에서 발생했는지 항상 전체를 검사해야 함
  - 검사할 수 있는 파일 디스크립터 개수 제한(최대 1024개)
  - 함수 호출 때마다 데이터 복사 필요
    - 원본 테이블은 관심 있는 파일 디스크립터를 마킹한 테이블
    - 내부 데이터를 변경해서 반환하는 테이블은 이벤트가 발생한 파일 디스크립터를 마킹한 테이블
    - 두 테이블의 목적이 다르기 때문에 원본 테이블 보존 필요(관심 있는 대상을 계속 `select()` 함수에 넘겨야하므로)



##### poll(c언어 서버)

- 기본적으로 여러 개의 파일을 다루는 방식은 `select()`와 동일
- 파일 디스크립터의 이벤트를 기다리고, 이벤트가 발생하면 poll에서의 블록이 해제되어 어떤 파일 디스크립터에 이벤트가 발생했는지 검사
- 장점
  - 단일 스레드로 여러 개의 파일 입출력을 처리 가능
  - `select()`처럼 표준 입력, 출력, 에러를 따로 감시할 필요 없음
  - 별다른 구조체 없이 타임아웃 설정
- 단점
  - 일부 UNIX 시스템은 poll을 지원하지 않음



##### epoll(c언어 서버)

- select와 poll의 단점을 해결하는 멀티플렉싱
- 커널에 관찰 대상에 대한 정보를 한번에 전달
- 관찰 대상의 범위나 내용에 변경이 있을 때에만 변경 사항을 알려줌
- 장점
  - 상태 변화를 확인하기 위해 전체 파일 디스크립터를 검사할 필요 없음
  - 커널에 상태 정보를 유지하기 때문에 관찰 대상 목록을 매번 전달할 필요 없음
- 단점
  - Linux select -> Windows select 변경은 비교적 간단하지만 Linux epoll -> Windows IOCP 변경은 상대적으로 복잡함
